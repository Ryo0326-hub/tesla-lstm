# -*- coding: utf-8 -*-
"""LSTM_stock_prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z58-gzfWpblHTp7v6Urpr57XYk3ZVCe5

Installing Alpaca API Package
"""

pip install alpaca-trade-api

import alpaca_trade_api as tradeapi

"""Endpoint: https://paper-api.alpaca.markets/v2

Key PKNIIOH2CJKEFBEX6TSJ Secret TJJMFsdP4bhH5NXAlZsUdRpgulHTxbold4d5UiNQ
"""

!pip install alpaca-py
import pandas as pd
from datetime import datetime, timedelta
import pytz

from alpaca.data.historical import StockHistoricalDataClient
from alpaca.data.requests import StockBarsRequest
from alpaca.data.timeframe import TimeFrame, TimeFrameUnit


# Exception handling (optional)
from alpaca.common.exceptions import APIError

# Securely input your Alpaca API credentials
API_KEY = "PKMZIOHORZ8VAE1ED0MS"
SECRET_KEY = "uCU6m83Xe0WsnEdNwq7hVRC8fKXJaywbo604yYxM"

# Install required packages
!pip install alpaca-py

# Import necessary libraries
import pandas as pd
from datetime import datetime, timedelta
import pytz
from getpass import getpass

from alpaca.data.historical import StockHistoricalDataClient
from alpaca.data.requests import StockBarsRequest
from alpaca.data.timeframe import TimeFrame, TimeFrameUnit
from alpaca.data.enums import DataFeed

# Initialize the historical data client
client = StockHistoricalDataClient(API_KEY, SECRET_KEY)

# Define the time range in UTC
end_date = datetime.now(pytz.utc)
start_date = end_date - timedelta(days=180 * 10)  # Approximately 6 months

# Create the request parameters with IEX feed (free data)
request_params = StockBarsRequest(
    symbol_or_symbols='TSLA',
    start=start_date,
    end=end_date,
    timeframe=TimeFrame(30, TimeFrameUnit.Minute),
    feed=DataFeed.IEX,  # Use IEX data feed
    limit=10000  # Adjust as needed
)

# Fetch the data
bars = client.get_stock_bars(request_params)

# Check if data is returned
if bars.df.empty:
    print("No data was returned. Please check your API access and parameters.")
else:
    # Convert the data to a pandas DataFrame
    tsla_data = bars.df.reset_index()

    # Display the first few rows
    print("First 5 rows of TSLA 30-minute interval data:")
    display(tsla_data.head())

    # Optionally, plot the closing prices
    tsla_data.set_index('timestamp', inplace=True)
    tsla_data['close'].plot(title='TSLA Close Prices over Past 6 Months (30-minute intervals)', figsize=(15,7))

    # Reset index for saving
    tsla_data.reset_index(inplace=True)

    # Save to CSV in Google Colab
    tsla_data.to_csv('tsla_30min_past6months.csv', index=False)
    print("\nData saved to 'tsla_30min_past6months.csv' in the Colab environment.")
    tsla_data.set_index('timestamp', inplace=True)
    tsla_data.index = tsla_data.index.tz_localize(None)

# get_tsla_data()

# Install required packages

# Securely input your Alpaca API credentials
API_KEY = 'CKBZKQVPM584191R1O8N'
SECRET_KEY = 'BS56fEij6a4v8FOHKDohmKdThjy4wep5dfC0YRre'
API_KEY = "PKMZIOHORZ8VAE1ED0MS"
SECRET_KEY = "uCU6m83Xe0WsnEdNwq7hVRC8fKXJaywbo604yYxM"
# Install the Alpaca SDK
!pip install --upgrade alpaca-py

# Import necessary libraries
import pandas as pd
from datetime import date, timedelta
from getpass import getpass

from alpaca.trading.client import TradingClient
from alpaca.trading.requests import GetCorporateAnnouncementsRequest
from alpaca.trading.enums import CorporateActionType, CorporateActionDateType

# Initialize the TradingClient
trading_client = TradingClient(API_KEY, SECRET_KEY)

# Define the total number of days you want to cover (approximately 5 years)
total_days = 365 * 5

# Initialize an empty DataFrame to store results
all_ca_df = pd.DataFrame()

# Calculate the number of intervals (API limits date range to 90 days)
num_intervals = (total_days // 90) + 1

for i in range(num_intervals):
    # Calculate the start and end dates for each interval
    end_date = date.today() - timedelta(days=90 * i)
    start_date = end_date - timedelta(days=90)
    # print(start_date)
    # print(end_date)

    if start_date < date.today() - timedelta(days=total_days):
        start_date = date.today() - timedelta(days=total_days)

    # Create request parameters
    ca_request_params = GetCorporateAnnouncementsRequest(
        ca_types=[CorporateActionType.SPLIT  ],
        since=start_date,
        until=end_date,
        symbol='TSLA',
        date_type=CorporateActionDateType.DECLARATION_DATE
    )

    # Fetch corporate announcements
    corporate_announcements = trading_client.get_corporate_announcements(ca_request_params)

    # Convert to DataFrame and append
    ca_df = pd.DataFrame([announcement.__dict__ for announcement in corporate_announcements])
    print(  ca_df)
    all_ca_df = pd.concat([all_ca_df, ca_df], ignore_index=True)

# Remove duplicates if any
# all_ca_df.drop_duplicates(subset='id', inplace=True)

# Display the results
if not all_ca_df.empty:
    print("Stock Splits for TSLA over the past 5 years:")
    display(all_ca_df)
else:
    print("No stock splits for TSLA over the past 5 years.")

import yfinance as yf
import pandas as pd  # Make sure to import pandas

# Specify the stock ticker
ticker = 'TSLA'  # Replace with any stock symbol you want

# Download the stock data
stock = yf.Ticker(ticker)

# Get stock split data and convert to DataFrame
splits = stock.splits
splits_df = pd.DataFrame(splits).reset_index()

# Rename columns for clarity
splits_df.columns = ['Date', 'Split Ratio']

# Convert the "Split Ratio" column to an array
split_array = splits_df['Split Ratio'].values
splits_df['Date'] = splits_df['Date'].dt.tz_localize(None)

# Display the DataFrame and the array
print(splits_df)
print("\nSplit Ratios as an array:")
print(split_array)

# Check if there are any splits
if not splits_df.empty:
    print(f"\nStock splits for {ticker}:")
    print(splits_df)
    print("\nSplit Ratios as an array:")
    print(split_array)
else:
    print(f"No stock splits found for {ticker}.")

import matplotlib.pyplot as plt
temp_num =0
for i in split_array:
  temp_num+=i
# print(temp_num)

for date, split_ratio in splits_df.values:
  print(date, split_ratio)
  print(date)
  temp_num = split_ratio
  date=pd.Timestamp(date)
        # Apply the cumulative adjustment to data before the split date
  tsla_data.loc[:date, 'close'] /= temp_num
  tsla_data.loc[:date, 'open'] /= temp_num
  tsla_data.loc[:date, 'high'] /= temp_num
  tsla_data.loc[:date, 'low'] /= temp_num
  tsla_data.loc[:date, 'volume'] *= temp_num  # Volume is adjusted by multiplying
  # tsla_data.loc[tsla_data['timestamp'] == date, 'close'] *= split_ratio
  # tsla_data.loc[tsla_data['timestamp'] == date, 'close'] *= split_ratio
tsla_data.to_csv('tsla_30min_past6months_processed.csv', index=False)

tsla_data.head()
plt.figure(figsize=(14, 7))
plt.plot(tsla_data.index, tsla_data['close'], label='Close Price', color='blue')
plt.title("TSLA Close Price Over Time")
plt.xlabel("Date")
plt.ylabel("Close Price (USD)")
plt.legend()
plt.show()

tsla_data.head(-5)

tsla_data.shape

# put that into LSTM model

#!pip install tensorflow
#!pip install scikit-learn
#!pip install pandas
#!pip install matplotlib

# Import libraries

 import numpy as np
 import pandas as pd
 import tensorflow as tf
 from tensorflow.keras.models import Sequential
 from tensorflow.keras.layers import Dense, LSTM, Dropout
 from sklearn.preprocessing import MinMaxScaler
 import matplotlib.pyplot as plt
 import datetime

 # import to ignore warnings
 import warnings
 warnings.filterwarnings('ignore')

tsla_data.head()

data = tsla_data[['close']]

# Step 2: Preprocess the data
# Initialize MinMaxScaler to normalize the data between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))

# Scale the data for training
scaled_data = scaler.fit_transform(data)

# Train-test split
import numpy as np

# Define the split ratio
train_size = int(len(scaled_data) * 0.8)
test_size = len(scaled_data) - train_size

# Split the data
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

# Function to create sequences with a sliding window
def create_dataset(data, time_step=30):
    X, y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:i+time_step])  # Sequence of past data
        y.append(data[i+time_step])   # Target: next day's value
    return np.array(X), np.array(y)

# Prepare the training and testing datasets
time_step = 30
X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)

#Convert lists to numpy array for model training
X_train = np.array(X_train)
y_train = np.array(y_train)
X_test = np.array(X_test)

#Reshape X_train to format [samples, time steps, features] required for the LSTM
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

#Building LSTM
model = Sequential()

#First LSTM layer with 50 unites and return sequences
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2)) # Dropout layer to prevent overfitting

#Second LSTM layer
model.add(LSTM(50, return_sequences=False))
model.add(Dropout(0.2))

#Dense Layer with 25 units
model.add(Dense(25))

# Output Layer with 1 unit (the predicted price)
model.add(Dense(units=1))

#Compile the model using "Adam" optimizer and mean squared error as the loss function
model.compile(optimizer='adam', loss='mean_squared_error')

# Training the model
# Train the model with batch size of 1 and 1 epoch (adjust epoch count for better results)

model.fit(X_train, y_train, batch_size=1, epochs=1)

# Step 6: Prepare the data for 30-days forcast
X_future = scaled_data.reshape((1, scaled_data.shape[0], 1))

# Generate 30 days forecast
# Create an empty list to store predcitions for the next 30 days
future_predictions = []
for _ in range(30):
  pred = model.predict(X_future)
  future_predictions.append(pred[0, 0])

#Update x_future with the new prediction by removing the first value
# and adding the new prediction.
X_future = np.append(X_future[:, 1:, :], [[pred[0]]], axis=1)

# Transform predictions back to original scale
# Convert the scaled predictions back to the original scale using inverse_transform

future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# Vizualization of the historical data and 30-day forecast

#Create dataframe to hold the 30-days forecast with dates
forecast_dates = pd.date_range(start=data.index[-1] + pd.Timedelta(days=1), periods=30)
forecast = pd.DataFrame(future_predictions, index=forecast_dates, columns=['Predictions'])

# Plot historical data and future predictions for comparison
plt.figure(figsize=(10, 5))
plt.plot(data['close'], label='Historical Prices')
plt.plot(forecast, label='30-Day Forecast', linestyle='--')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

# Predict on the training and test data
train_predictions = model.predict(X_train)
test_predictions = model.predict(X_test)

# Inverse transform predictions and actual values
train_predictions = scaler.inverse_transform(train_predictions)
test_predictions = scaler.inverse_transform(test_predictions)
y_train_actual = scaler.inverse_transform(y_train.reshape(-1, 1))
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

import numpy as np

# Combine the datasets
train_plot = np.empty_like(scaled_data)
train_plot[:, :] = np.nan
train_plot[time_step:len(train_predictions)+time_step, :] = train_predictions

test_plot = np.empty_like(scaled_data)
test_plot[:, :] = np.nan
test_plot[len(train_predictions)+(time_step*2):len(scaled_data), :] = test_predictions

import matplotlib.pyplot as plt

# Plot the data
plt.figure(figsize=(12, 6))
plt.plot(scaler.inverse_transform(scaled_data), label='Actual Values', color='blue')
plt.plot(train_plot, label='Train Predictions', color='green')
plt.plot(test_plot, label='Test Predictions', color='red')
plt.title('Model Predictions vs Actual Values')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error
import math

# Training metrics
train_mse = mean_squared_error(y_train_actual, train_predictions)
train_rmse = math.sqrt(train_mse)

# Test metrics
test_mse = mean_squared_error(y_test_actual, test_predictions)
test_rmse = math.sqrt(test_mse)

print(f"Training RMSE: {train_rmse}")
print(f"Test RMSE: {test_rmse}")